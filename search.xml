<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JDK在Linux上部署指南]]></title>
    <url>%2Fposts%2F2018%2F01%2F10%2FJDK%E5%9C%A8Linux%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[部署说明以 jdk7 为例，其他版本同理。 安装包 jdk-7u80-linux-x64.tar.gz部署流程进入安装目录，执行：12345[root@test ~]# cd /usr/local/[root@test local]# tar zxf jdk-7u80-linux-x64.tar.gz [root@test local]# lsbin etc games include jdk1.7.0_80 jdk-7u80-linux-x64.tar.gz lib lib64 libexec sbin share src[root@test local]# rm -f jdk-7u80-linux-x64.tar.gz 编辑 /etc/profile12345################### jdk-7u80 ##############################export JAVA_HOME=/usr/local/jdk1.7.0_80export JRE_HOME=/usr/local/jdk1.7.0_80/jreexport CLASSPATH=.:/usr/local/jdk1.7.0_80/lib:/usr/local/jdk1.7.0_80/jre/libexport PATH=$&#123;PATH&#125;:$&#123;JAVA_HOME&#125;/bin 立即生效1source /etc/profile 查验部署1234[root@test local]# java -versionjava version "1.7.0_80"Java(TM) SE Runtime Environment (build 1.7.0_80-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode) 如上图所示，表示部署成功。]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>j[jdk]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch5.6.4在CentOS6.7上的部署指南]]></title>
    <url>%2Fposts%2F2018%2F01%2F10%2FElasticSearch5-6-4%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[环境说明ES（ElasticSearch）依赖于 Java 环境，要先安装 JDK，ElasticSearch5.6.4要求最低Java8版本，参考《JDK在Linux上部署指南》 部署说明安装包 elasticsearch-5.6.4.tar.gz部署流程创建用户ES 只能用普通用户启动服务，首先给所有节点创建一个普通用户用来安装。12useradd elasticpasswd elastic 使用 ROOT 用户操作，进入安装目录12345cd /usr/localtar zxf elasticsearch-5.6.4.tar.gzrm -f elasticsearch-5.6.4.tar.gzchown -R elastic:elastic elasticsearch-5.6.4chmod -R +x elasticsearch-5.6.4 通过 /etc/security/limits.conf 设置 max file descriptors123elastic soft memlock unlimitedelastic hard memlock unlimitedelastic - nofile 65536 通过 /etc/security/limits.d/90-nproc.conf 设置 max number of threads12* soft nproc 2048root soft nproc unlimited 通过 /etc/sysctl.conf 设置 max virtual memory areas1vm.max_map_count = 262144 sysctl -p 使配置立即生效，然后重启机器。 切换为前面创建的 ES 用户1su elastic 编辑 ES 配置 elasticsearch-5.6.4/config/elasticsearch.yml1234567cluster.name: first-clusternode.name: node-1bootstrap.memory_lock: true #开启内存锁要求禁用交换分区network.host: 192.168.0.110 # 集群要求非回环地址http.port: 9200discovery.zen.ping.unicast.hosts: ["192.168.0.110"]bootstrap.system_call_filter: false 注意：冒号后面有个空格 如果开启内存锁，还要禁用交换分区临时禁用：1swapoff -a 编辑 /etc/fstab 文件并且注释掉任何包含 swap 的行来永久禁用， 运行 ES：1elasticsearch-5.6.4/bin/elasticsearch -d 查验系统用浏览器访问 http://192.168.0.110:9200 附录进阶配置设置 jvm 堆大小，通过 jvm.optionsES 默认使用 jvm 最小和最大堆大小为 2GB.当在生产环境部署时，必须确保 ES 有足够可用的堆。 配置经验总结： Xms 和 Xmx相等 ES 分配的堆越多，能用来缓存的内存越多。但是设置太大的堆会造成太长的垃圾回收延长. Xmx 不超过物理内存的 50%，确保剩下的内存够内核文件系统缓存。 Xmx 不要超过 jvm 使用 compressed object pointers (compressed oops)阈值。准确的阈值是变化的但是接近 32GB。你可以看到你正处于某个阈值下，通过找到日志中像下面的一行： 1heap size [247.6mb], compressed ordinary object pointers [true] 更好的是，尝试保持 zero-based compressed oops 在阈值之下。准确的阈值是变化的但是 26GB 在大多数机器上是安全的，有些系统能达到 30GB。你可以看到你正处于某个界限下，通过启动 ES 时加上 jvm 参数：-XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode，在日志中找到像下面的一行： 1heap address: 0x000000011be00000, size: 27648 MB, zero based Compressed Oops 像下面一行，如果启用 zero-based compressed oops 1heap address: 0x0000000118400000, size: 28672 MB, Compressed Oops with base: 0x00000001183ff000 下面是 jvm.options 文件设置堆大小例子：12345# Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms256m-Xmx256m 安装 SQL 插件On elasticsearch 1.x / 2.x, visit the elasticsearch-sql web front-end:1http://localhost:9200/_plugin/sql/ On elasticsearch 5.x, download and extract site. Then start the web front-end like this: 12345678910cd site-server# install nodejs# On RHEL, CentOS or Fedora, for Node.js v6 LTS:curl --silent --location https://rpm.nodesource.com/setup_8.x | sudo bash -# then install gaw安装nodejs可能有问题yum install -y gcc-c++ make nodejsnpm install express --savenode node-server.js &amp;# 端口号在 site_configuration.json 中指定 安装 HEAD 插件123456git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm installnpm run start &amp;open http://localhost:9100/ kopf 插件不再维护，用还在维护的 cerebro 替代1234Download from https://github.com/lmenezes/cerebro/releasesExtract filesRun bin/cerebro(or bin/cerebro.bat if on Windows)Access on http://localhost:9000 常见问题注意事项]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVM在CentOS6.7上的配置指南]]></title>
    <url>%2Fposts%2F2017%2F12%2F27%2FLVM%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[LVM简介LVM 是一种可用在Linux内核的逻辑分卷管理器；可用于管理磁盘驱动器或其他类似的大容量存储设备。 LVM基本组成LVM的基本组成块（building blocks）如下： 物理卷Physical volume (PV)：可以在上面建立卷组的媒介，可以是硬盘分区，也可以是硬盘本身或者回环文件（loopback file）。物理卷包括一个特殊的header，其余部分被切割为一块块物理区域（physical extents）。 Think of physical volumes as big building blocks which can be used to build your hard drive. 卷组Volume group (VG)：将一组物理卷收集为一个管理单元。Group of physical volumes that are used as storage volume (as one disk). They contain logical volumes. Think of volume groups as hard drives. 逻辑卷Logical volume (LV)：虚拟分区，由物理区域（physical extents）组成。A “virtual/logical partition” that resides in a volume group and is composed of physical extents. Think of logical volumes as normal partitions. 物理区域Physical extent (PE)：硬盘可供指派给逻辑卷的最小单位（通常为4MB）。A small part of a disk (usually 4MB) that can be assigned to a logical Volume. Think of physical extents as parts of disks that can be allocated to any partition. 示例: 123456789101112131415161718192021两块物理硬盘 硬盘1 (/dev/sda): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |分区1 50GB (物理卷) |分区2 80GB (物理卷) | |/dev/sda1 |/dev/sda2 | |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _|_ _ _ _ _ _ _ _ _ _ _ _ _ _ __| 硬盘2 (/dev/sdb): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |分区1 120GB (物理卷) | |/dev/sdb1 | | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _|LVM方式卷组VG1 (/dev/MyStorage/ = /dev/sda1 + /dev/sda2 + /dev/sdb1): _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ __ |逻辑卷1 15GB |逻辑卷2 35GB |逻辑卷3 200GB | |/dev/MyStorage/rootvol |/dev/MyStorage/homevol |/dev/MyStorage/mediavol | |_ _ _ _ _ _ _ _ _ _ _ _ _ _ __|_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ __ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _| 优点比起正常的硬盘分区管理，LVM更富于弹性： 使用卷组(VG)，使众多硬盘空间看起来像一个大硬盘。 使用逻辑卷（LV），可以创建跨越众多硬盘空间的分区。 可以创建小的逻辑卷（LV），在空间不足时再动态调整它的大小。 在调整逻辑卷（LV）大小时可以不用考虑逻辑卷在硬盘上的位置，不用担心没有可用的连续空间。It does not depend on the position of the LV within VG, there is no need to ensure surrounding available space. 可以在线（online）对逻辑卷（LV）和卷组（VG）进行创建、删除、调整大小等操作。LVM上的文件系统也需要重新调整大小，某些文件系统也支持这样的在线操作。 无需重新启动服务，就可以将服务中用到的逻辑卷（LV）在线（online）/动态（live）迁移至别的硬盘上。 允许创建快照，可以保存文件系统的备份，同时使服务的下线时间（downtime）降低到最小。缺点 在系统设置时需要更复杂的额外步骤。在 CentOS 上使用 LVM操作流程 创建物理卷（PV）所在的分区，设置分区格式为’Linux LVM’，对应的十六进制码为8e（MBR）或8e00（GPT）。 创建物理卷（PV）。如果你只有一个硬盘，那么你最好只创建一个分区一个物理卷；如果你有多个硬盘，你可以创建多个分区，在每个分区上分别创建一个物理卷。 创建卷组（VG），并把所有物理卷加进卷组。 在卷组上创建逻辑卷（LV）。 继续CentOS6-7下磁盘分区操作指南中的格式化分区，挂载分区，设置开机自动挂载步骤。创建分区12345678910111213141516[root@hadoop-01 ~]# fdisk /dev/sdbCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-2610, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-2610, default 2610): Using default value 2610Command (m for help): t Selected partition 1Hex code (type L to list codes): 8eChanged system type of partition 1 to 8e (Linux LVM) 前面和CentOS6-7下磁盘分区操作指南中新建分区一样，多一步改变分区类型。设置分区格式为’Linux LVM’，对应的十六进制码为8e（MBR）或8e00（GPT）。 创建物理卷（PV）可通过以下命令列出可被用作物理卷的设备：1lvmdiskscan 警告: 请确认你对正确的设备进行操作，否则会导致文件丢失！ 在列出的设备上创建物理卷：1pvcreate DEVICE 该命令在各个设备上创建LVM使用的头部。如#LVM基本组成所示, DEVICE可以是磁盘（如/dev/sda），分区（如/dev/sda2）或环回设备。例如：1pvcreate /dev/sda2 你可以用以下命令查看已创建好的物理卷：1pvdisplay 使用下列命令可以删除物理卷。1pvremove /dev/sda2 创建卷组（VG）1vgcreate &lt;volume_group&gt; &lt;physical_volume&gt; 例如：1vgcreate VolGroup00 /dev/sda2 然后让该卷组扩大到其他所有的物理卷: 123vgextend &lt;volume_group&gt; &lt;physical_volume&gt;vgextend &lt;volume_group&gt; &lt;another_physical_volume&gt;... 例如： 12vgextend VolGroup00 /dev/sdb1vgextend VolGroup00 /dev/sdc 接下来可以用以下命令查看卷组：1#vgdisplay 使用下列命令删除卷组。1#vgremove volume-group1 一步创建卷组LVM支持将卷组与物理卷的创建聚合在一个命令中。例如，为了在前文提到的三个设备中创建名为VolGroup00的卷组，可以执行如下命令：1#vgcreate VolGroup00 /dev/sda2 /dev/sdb1 /dev/sdc 创建逻辑卷（LV）1#lvcreate -L &lt;size&gt; &lt;volume_group&gt; -n &lt;logical_volume&gt; 例如：1#lvcreate -L 10G VolGroup00 -n lvolhome 如果你想让要创建的逻辑卷拥有卷组（VG）的所有未使用空间，请使用以下命令： 1#lvcreate -l +100%FREE &lt;volume_group&gt; -n &lt;logical_volume&gt; 可以通过以下命令来查看逻辑卷：1#lvdisplay 建立文件系统与挂载逻辑卷参考CentOS6-7下磁盘分区操作指南中的格式化分区，挂载分区，设置开机自动挂载步骤。 高级选项物理卷扩增增大分区/dev/sda1的容量之后，需要执行以下命令扩展物理卷的大小1#pvresize /dev/sda1 逻辑卷使用 lvresize 增加或缩小容量为了向逻辑组 vg1 中的逻辑卷 lv1 增加 2GB 空间但并不修改其文件系统，执行：1#lvresize -L +2G vg1/lv1 而从逻辑组 vg1 中的逻辑卷 lv1 中减少 500MB 空间但并不修改其文件系统大小（需要确保文件系统已经缩小过），执行：1#lvresize -L -500M vg1/lv1 设置vg1/lv1为15GB并同时更改其文件系统大小：1#lvresize -L 15G -r vg1/lv1 注意: 仅支持ext2, ext3, ext4, ReiserFS and XFS file systems。如果使用不同文件系统请使用合适的组件。 如果想将所有可用空间都加入一个卷组，可以执行：1#lvresize -l +100%FREE vg/lv 移除逻辑卷警告: 在移除逻辑卷之前，请先备份好数据以免丢失！ 首先，找到你所要移除的逻辑卷的名称。你可以使用以下命令来查看系统的所有逻辑卷：1lvs 接下来，找到你所要移除的逻辑卷的挂载点1$ lsblk 并卸载它：1umount /&lt;mountpoint&gt; 最后，使用以下命令来移除逻辑卷：1lvremove &lt;volume_group&gt;/&lt;logical_volume&gt; 例如：1lvremove VolGroup00/lvolhome 请输入y来确定你要执行移除逻辑卷操作。 此外，请不要忘了更新 /etc/fstab。 你可以再次使用 lvs 命令来确认你的逻辑卷已被移除。 如果提示 logical volume in use lvremove，重启机器（在/etc/fstab里注释，否则开机会再次挂载）。 从卷组（VG）中移除分区首先，分区中的所有数据需要被转移到别的分区，幸而LVM提供了以下的简便方式：1pvmove /dev/sdb1 如果你想指定所要转移的目标分区，那么可以把该分区作为pvmove的第二个参数：1pvmove /dev/sdb1 /dev/sdf1 接着，从卷组（VG）中移除物理卷（PV）：1vgreduce myVg /dev/sdb1 或者把所有的空物理卷（PV）都移除掉：1vgreduce --all vg0 最后，如果你仍然想要使用该分区，而且不想让LVM以为它是一个物理卷，那么你可以执行以下命令：1pvremove /dev/sdb1 常见问题LVM 命令不起作用加载以下模块:1modprobe dm_mod 逻辑卷无法显示如果你在挂载某个已创建好的逻辑卷时，发现它没有出现在lvscan命令的结果列表里，那么你可以用以下命令去激活它：12vgscanvgchange -ay 参考（copy）文档LVM (简体中文) - ArchWiki)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>LVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[定时任务Cron在CentOS6.7上安装指南]]></title>
    <url>%2Fposts%2F2017%2F12%2F26%2F%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1Cron%E5%9C%A8CentOS6-7%E4%B8%8A%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[安装123456# 安装yum install -y vixie-cron crond# 设置开机自启chkconfig crond on# 启动service crond start Crontab 格式12345678# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 注： 在“星期域”（第五个域），0和7都被视为星期日。 不很直观的用法：如果日期和星期同时被设定，那么其中的一个条件被满足时，指令便会被执行。请参考下例。 前5个域称之分时日月周，可方便个人记忆。 从第六个域起，指明要执行的命令。 基本命令Crontabs 不应该直接编辑；用户应该使用 crontab 程序来处理他们的 crontabs。为了能够访问这个命令，用户必须添加到 users 用户组 (见 gpasswd 命令). 1234567891011[root@solr1 ~]# crontab --helpcrontab: invalid option -- '-'crontab: usage error: unrecognized optionusage: crontab [-u user] file crontab [-u user] [ -e | -l | -r ] (default operation is replace, per 1003.2) -e (edit user's crontab) -l (list user's crontab) -r (delete user's crontab) -i (prompt before deleting user's crontab) -s (selinux context) 添加调度计划 一种是直接编辑，执行crontab -e，然后输入调度表达式 如果用户有一个保存好的 crontab 想要用它完全覆盖旧的 crontab，可以使用： crontab saved_crontab_filename 栗子12345678910#偶数小时内每分钟执行一次* 0,2,4,6,8,10,12,14,16,18,20,22 * * * date &gt;&gt; /var/log/date.log #两个小时执行一次0 0,2,4,6,8,10,12,14,16,18,20,22 * * * date &gt;&gt; /var/log/date.log # an even better way0 */2 * * * date &gt;&gt; /var/log/date.log#每天凌晨执行 0 0 * * * date &gt;&gt; /var/log/date.log #两分钟执行一次 */2 * * * * date &gt;&gt; /var/log/date.log 注意事项不发送电子邮件如果输出结果来自crontab里的命令，那么cron守护进程会用电子邮件将它发给用户 若想关闭某个命令的输出结果，可以将输出结果重定向至/dev/null。 1&gt;/dev/null 2&gt;&amp;1 在常用的Vixie cron中，也可以在文件的开始部分加入命令来关闭所有命令的邮件输出： 1MAILTO="" 常见问题crond不执行原因分析：没有使用绝对路径包括crond命令和脚本 crontab不提供所执行用户的环境变量解决方法：在脚本中加入下面这一行：1. /etc/profile 或者导入环境变量(例如Java环境)：1export JAVA_HOME=/usr/local/java 脚本没有可执行权限在crontab中建议使用 sh 或 bash 来执行shell脚本，避免因脚本文件的执行权限丢失导致任务失败。 放大招：查看日志1tail /var/log/cron 表达式最小支持分钟，如果想按照秒执行呢12345step=5 #间隔的秒数for (( i = 0; i &lt; 60; i=(i+step) )); do yourcommond sleep $step done 脚本里通过for循环，能够按秒执行。 如果60不能整除间隔的秒数，则需要调整执行的时间。例如需要每7秒执行一次，就需要找到7与60的最小公倍数，7与60的最小公倍数是420（即7分钟）。则crontab.sh中step的值为7，循环结束条件i&lt;420， crontab -e可以输入以下语句来实现1*/7 * * * * yourcommond]]></content>
      <categories>
        <category>Linux</category>
        <category>Cron</category>
      </categories>
      <tags>
        <tag>Cron</tag>
        <tag>定时任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper3.4.6在CentOS6.7上的部署指南]]></title>
    <url>%2Fposts%2F2017%2F11%2F24%2Fzookeeper3-4-6%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[前言部署流程安装 JDK，安装 Zookeeper 附录配置自动清理日志开启 snapshot 日志和事务日志自动清理从3.4.0开始，zookeeper提供了自动清理 snapshot 和事务日志的功能，修改${ZK_HOME}/conf/zoo.cfg文件：12autopurge.purgeInterval: 1 , //这个参数指定了清理频率，单位是小时。默认是0，表示不开启自己清理功能。autopurge.snapRetainCount: 3 //这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。 log4j 日志自动清理编辑 ${ZK_HOME}/conf/log4j.proerties 文件：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# Define some default values that can be overridden by system propertieszookeeper.root.logger=INFO,ROLLINGFILEzookeeper.console.threshold=INFOzookeeper.log.dir=.zookeeper.log.file=zookeeper.logzookeeper.log.threshold=DEBUGzookeeper.tracelog.dir=.zookeeper.tracelog.file=zookeeper_trace.log## ZooKeeper Logging Configuration## Format is &quot;&lt;default threshold&gt; (, &lt;appender&gt;)+# DEFAULT: console appender onlylog4j.rootLogger=$&#123;zookeeper.root.logger&#125;# Example with rolling log file#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE# Example with rolling log file and tracing#log4j.rootLogger=TRACE, CONSOLE, ROLLINGFILE, TRACEFILE## Log INFO level and above messages to the console#log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Threshold=$&#123;zookeeper.console.threshold&#125;log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d&#123;ISO8601&#125; [myid:%X&#123;myid&#125;] - %-5p [%t:%C&#123;1&#125;@%L] - %m%n## Add ROLLINGFILE to rootLogger to get log file output# Log DEBUG level and above messages to a log filelog4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.ROLLINGFILE.Threshold=$&#123;zookeeper.log.threshold&#125;log4j.appender.ROLLINGFILE.File=$&#123;zookeeper.log.dir&#125;/$&#123;zookeeper.log.file&#125;# Max log file size of 10MBlog4j.appender.ROLLINGFILE.MaxFileSize=100MB# uncomment the next line to limit number of backup fileslog4j.appender.ROLLINGFILE.MaxBackupIndex=30log4j.appender.ROLLINGFILE.layout=org.apache.log4j.PatternLayoutlog4j.appender.ROLLINGFILE.layout.ConversionPattern=%d&#123;ISO8601&#125; [myid:%X&#123;myid&#125;] - %-5p [%t:%C&#123;1&#125;@%L] - %m%n## Add TRACEFILE to rootLogger to get log file output# Log DEBUG level and above messages to a log filelog4j.appender.TRACEFILE=org.apache.log4j.FileAppenderlog4j.appender.TRACEFILE.Threshold=TRACElog4j.appender.TRACEFILE.File=$&#123;zookeeper.tracelog.dir&#125;/$&#123;zookeeper.tracelog.file&#125;log4j.appender.TRACEFILE.layout=org.apache.log4j.PatternLayout### Notice we are including log4j&apos;s NDC here (%x)log4j.appender.TRACEFILE.layout.ConversionPattern=%d&#123;ISO8601&#125; [myid:%X&#123;myid&#125;] - %-5p [%t:%C&#123;1&#125;@%L][%x] - %m%n 常见问题阿里云 ECS 上 Zookeeper 部署 zoo.cfg 中本机器 IP 地址公网访问配置为 0.0.0.0，内网访问配置为内网 ip 地址。 zookerper 使用的端口需要确认在系统防火墙及ECS实例安全组规则里允许访问。 zoo.cfg栗子(server.1机器上)：123server.1=0.0.0.0:2888:3888server.2=10.120.1.11:2888:3888server.3=10.120.1.12:2888:3888 查看zk状态时报Error contacting service. It is probably not running1234[root@sso conf]# zkServer.sh statusJMX enabled by defaultUsing config: /var/local/server/zookeeper/bin/../conf/zoo.cfgError contacting service. It is probably not running. 没有创建数据目录和日志目录 查看日志]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.7下多网卡绑定配置指南]]></title>
    <url>%2Fposts%2F2017%2F11%2F22%2FCentOS6-7%E4%B8%8B%E5%A4%9A%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[前言Linux 网卡绑定 mode 共有七种(0~6) bond0、bond1、bond2、bond3、bond4、bond5、bond6. 常用的有三种 mode=0：平衡负载模式，有自动备援，需要交换机设置。使用mode0时与网卡相连的交换机必须做特殊配置（这两个端口应该采取聚合方式） mode=1：自动备援模式，其中一条线若断线，其他线路将会自动备援。 mode=6：平衡负载模式，有自动备援。 七种模式说明mode=0mode=0，即：(balance-rr) Round-robin policy（平衡抡循环策略）。 特点：传输数据包顺序是依次传输（即：第1个包走eth0，下一个包就走eth1….一直循环下去，直到最后一个传输完毕），此模式提供负载平衡和容错能力；但是我们知道如果一个连接或者会话的数据包从不同的接口发出的话，中途再经过不同的链路，在客户端很有可能会出现数据包无序到达的问题，而无序到达的数据包需要重新要求被发送，这样网络的吞吐量就会下降 mode=1mode=1，即： (active-backup) Active-backup policy（主-备份策略）。 特点：只有一个设备处于活动状态，当一个宕掉另一个马上由备份转换为主设备。mac地址是外部可见得，从外面看来，bond的MAC地址是唯一的，以避免switch(交换机)发生混乱。此模式只提供了容错能力；由此可见此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有 N 个网络接口的情况下，资源利用率为1/N mode=2mod=2，即：(balance-xor) XOR policy（平衡策略） 特点：基于指定的传输HASH策略传输数据包。缺省的策略是：(源MAC地址 XOR 目标MAC地址) % slave数量。其他的传输策略可以通过xmit_hash_policy选项指定，此模式提供负载平衡和容错能力 mode=3mod=3，即：broadcast（广播策略） 特点：在每个slave接口上传输每个数据包，此模式提供了容错能力 mode=4mod=4，即：(802.3ad) IEEE 802.3ad Dynamic link aggregation（IEEE 802.3ad 动态链接聚合） 特点：创建一个聚合组，它们共享同样的速率和双工设定。根据802.3ad规范将多个slave工作在同一个激活的聚合体下。外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要注意的 是，并不是所有的传输策略都是802.3ad适应的，尤其考虑到在802.3ad标准43.2.4章节提及的包乱序问题。不同的实现可能会有不同的适应 性。 必要条件： 条件1：ethtool支持获取每个slave的速率和双工设定 条件2：switch(交换机)支持IEEE 802.3ad Dynamic link aggregation 条件3：大多数switch(交换机)需要经过特定配置才能支持802.3ad模式mode=5mod=5，即：(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡） 特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。该模式的必要条件：ethtool支持获取每个slave的速率 mode=6mode=6，即：(balance-alb) Adaptive load balancing（适配器适应性负载均衡） 特点：该模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡(receive load balance, rlb)，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。bonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个slave的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。 来自服务器端的接收流量也会被均衡。当本机发送ARP请求时，bonding驱动把对端的IP信息从ARP包中复制并保存下来。当ARP应答从对端到达 时，bonding驱动把它的硬件地址提取出来，并发起一个ARP应答给bond中的某个slave。使用ARP协商进行负载均衡的一个问题是：每次广播 ARP请求时都会使用bond的硬件地址，因此对端学习到这个硬件地址后，接收流量将会全部流向当前的slave。这个问题可以通过给所有的对端发送更新 （ARP应答）来解决，应答中包含他们独一无二的硬件地址，从而导致流量重新分布。当新的slave加入到bond中时，或者某个未激活的slave重新 激活时，接收流量也要重新分布。接收的负载被顺序地分布（round robin）在bond中最高速的slave上。 当某个链路被重新接上，或者一个新的slave加入到bond中，接收流量在所有当前激活的slave中全部重新分配，通过使用指定的MAC地址给每个 client发起ARP应答。下面介绍的updelay参数必须被设置为某个大于等于switch(交换机)转发延时的值，从而保证发往对端的ARP应答 不会被switch(交换机)阻截。 必要条件： 条件1：ethtool支持获取每个slave的速率； 条件2：底层驱动支持设置某个设备的硬件地址，从而使得总是有个slave(curr_active_slave)使用bond的硬件地址，同时保证每个bond 中的slave都有一个唯一的硬件地址。如果curr_active_slave出故障，它的硬件地址将会被新选出来的 curr_active_slave接管 mod=6与mod=0的区别：mod=6，先把eth0流量占满，再占eth1，….ethX；而mod=0的话，会发现2个口的流量都很稳定，基本一样的带宽。而mod=6，会发现第一个口流量很高，第2个口只占了小部分流量。 配置流程0. 流程说明2 个物理网口分别是： eth0 , eth1 绑定后的虚拟口是：bond0 服务器 IP 是：192.168.1.115 1. 配置网卡1service NetworkManager stop # 关闭NetworkManager服务，如果没有NetworkManager服务可以忽略 12cd /etc/sysconfig/network-scripts/cp ifcfg-eth0 ifcfg-bond0 vim /etc/sysconfig/network-scripts/ifcfg-bond012345678DEVICE=bond0BOOTPROTO=noneONBOOT=yesIPADDR=192.168.1.115NETMASK=255.255.255.0NETWORK=192.168.0.0BROADCAST=192.168.1.255#BROADCAST广播地址 vim /etc/sysconfig/network-scripts/ifcfg-eth01234DEVICE=eth0BOOTPROTO=noneMASTER=bond0SLAVE=yes vim /etc/sysconfig/network-scripts/ifcfg-eth11234DEVICE=eth1BOOTPROTO=noneMASTER=bond0SLAVE=yes 2. 修改 modprobe 相关设定文件，并加载 bonding 模块 在这里，我们直接创建一个加载 bonding 的专属设定文件 /etc/modprobe.d/bonding.conf 12345vim /etc/modprobe.d/bonding.conf#追加alias bond0 bondingoptions bonding mode=6 miimon=80 加载模块(重启系统后就不用手动再加载了) 1[root@test ~]# modprobe bonding 确认模块是否加载成功： 12[root@hadoop-01 network-scripts]# lsmod | grep bondingbonding 132885 0 3. 重启一下网络，检查设置是否生效service network restart ，如果没生效，重启试试。123456789101112131415161718192021222324[root@hadoop-01 network-scripts]# cat /proc/net/bonding/bond0Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: load balancing (round-robin)MII Status: upMII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: eth0MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:ff:5d:a0Slave queue ID: 0Slave Interface: eth1MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:ff:5d:aaSlave queue ID: 0 1234567[root@hadoop-01 network-scripts]# ifconfig | grep HWaddrbond0 Link encap:Ethernet HWaddr 00:0C:29:FF:5D:A0 bond1 Link encap:Ethernet HWaddr 00:0C:29:FF:5D:B4 eth0 Link encap:Ethernet HWaddr 00:0C:29:FF:5D:A0 eth1 Link encap:Ethernet HWaddr 00:0C:29:FF:5D:A0 eth2 Link encap:Ethernet HWaddr 00:0C:29:FF:5D:B4 eth3 Link encap:Ethernet HWaddr 00:0C:29:FF:5D:B4 可以看出： 现在的 bonding 模式是 round-robin 即 mode = 0 bond0 , eth1 的物理地址和 eth0 的物理地址相同，这样是为了避免上位交换机发生混乱。 4. 系统启动自动绑定、增加默认网关 /etc/rc.d/rc.local123 #追加ifenslave bond0 eth0 eth1ifenslave bond1 eth2 eth3 前面只是2个网口绑定成一个bond0的情况，如果我们要设置多个bond口，比如物理网口eth0和eth1组成bond0，eth2和eth3组成bond1，那么网口设置文件的设置方法和上面第1步讲的方法相同，只是 /etc/modprobe.d/bonding.conf 的设定就不能像下面这样简单的叠加了： 正确的设置方法有2种： 第一种,你可以看到，这种方式的话，多个bond口的模式就只能设成相同的了： 12345alias bond0 bondingalias bond1 bondingoptions bonding max_bonds=2 miimon=80 mode=6 第二种，这种方式，不同的bond口的mode可以设成不一样： 12345alias bond0 bondingoptions bonding mode=6 miimon=80install bond1 /sbin/modprobe bonding -o bond1 miimon=100 mode=1 附录 参考资料： http://www.cnblogs.com/archoncap/p/6079915.html mode 1、5、6 不需要交换机设置 mode 0、2、3、4 需要交换机设置 缺省使用mode 0 Mode 0－（balance-rr）轮询模式，所绑定的网卡会针对访问以轮询算法进行平分。第一个请求来了发送给第一块网卡处理，第二个请求来了，就发往第二块网卡进行处理，以此提供负载均衡能力。但此模式没有容错能力，即只要有一块网卡不能正常工作，则会出错。 Mode 1－（active-backup）高可用模式，运行时只使用一个网卡，其余网卡作为备份，在负载不超过单块网卡带宽或压力时建议使用。只有当正在工作的网卡出故障时备用网卡才会被激活，并及时替换坏了的网卡进行工作，可见这个模式并不能提升数据处理性能，但是有容错能力，因此常运用在实际生产环境中。 Mode 2－基于HASH算法的负载均衡模式，网卡的分流按照xmit_hash_policy的TCP协议层设置来进行HASH计算分流，使各种不同处理来源的访问都尽量在同一个网卡上进行处理。 Mode 3－广播模式，所有被绑定的网卡都将得到相同的数据，一般用于十分特殊的网络需求，如需要对两个互相没有连接的交换机发送相同的数据。 Mode 4－802.3ab负载均衡模式，要求交换机也支持802.3ab模式，理论上服务器及交换机都支持此模式时，网卡带宽最高可以翻倍(如从1Gbps翻到2Gbps) Mode 5－适配器输出负载均衡模式，输出的数据会通过所有被绑定的网卡输出，接收数据时则只选定其中一块网卡。如果正在用于接收数据的网卡发生故障，则由其他网卡接管，要求所用的网卡及网卡驱动可通过ethtool命令得到speed信息。 Mode 6－适配器输入/输出负载均衡模式，在”模式5″的基础上，在接收数据的同时实现负载均衡，除要求ethtool命令可得到speed信息外，还要求支持对网卡MAC地址的动态修改功能。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>多网卡绑定</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Error occurred during initialization of VM问题]]></title>
    <url>%2Fposts%2F2017%2F11%2F14%2Fjvm%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[12345[root@8b408b62a5e2 jdk1.7.0_80]# javaError occurred during initialization of VMCould not reserve enough space for object heapError: Could not create the Java Virtual Machine.Error: A fatal exception has occurred. Program will exit. 今天遇到 jvm 问题，花费了一天才解决。是安装过 Greenplum 的原因。 查看内核参数 overcommit_memory12[root@localhost local]# cat /etc/sysctl.conf | grep overcommit_memoryvm.overcommit_memory=2 它是内存分配策略，可选值： 0、1 、2 。 0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2， 表示内核允许分配超过所有物理内存和交换空间总和的内存 Greenplum 要求 vm.overcommit_memory 值为 2 。修改vm.overcommit_memory=1，然后sysctl -p 使配置文件生效即可。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.7磁盘分区与挂载操作指南]]></title>
    <url>%2Fposts%2F2017%2F11%2F10%2FCentOS6-7%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E4%B8%8E%E6%8C%82%E8%BD%BD%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[简介本文介绍使用 fdisk 和 parted 进行磁盘分区。其中 fdisk 只能对 2T 以下磁盘分区。 操作流程总体说明磁盘分区的步骤为首先新建分区，然后格式化分区，之后挂载到目录，最后设置开机自动挂载。 新建分区使用 fdisk 分区查看磁盘信息，发现磁盘 /dev/sdb 还没有分区1234567891011121314151617181920[root@hadoop-01 ~]# fdisk -lDisk /dev/sda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x0004c41d Device Boot Start End Blocks Id System/dev/sda1 * 1 64 512000 83 LinuxPartition 1 does not end on cylinder boundary./dev/sda2 64 2611 20458496 8e Linux LVMDisk /dev/sdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 开始分区12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@hadoop-01 ~]# fdisk /dev/sdbDevice contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x93880d11.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won't be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u').Command (m for help): pDisk /dev/sdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x93880d11 Device Boot Start End Blocks Id SystemCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-2610, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-2610, default 2610): Using default value 2610Command (m for help): pDisk /dev/sdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x93880d11 Device Boot Start End Blocks Id System/dev/sdb1 1 2610 20964793+ 83 LinuxCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.[root@hadoop-01 ~]# 简单总结就是：12345678fdisk /dev/sdbn p1回车回车pw 每个命令的含义：123456789101112131415161718Command (m for help): mCommand action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) 然后再执行 fdisk -l 看到已经分区。123456789Disk /dev/sdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x93880d11 Device Boot Start End Blocks Id System/dev/sdb1 1 2610 20964793+ 83 Linux 使用 parted 分区：与 fdisk 分区工具相比， parted 支持 2TB 以上的磁盘分区，并且允许调整分区的大小。 如果没有 parted 命令，使用 yum 安装 yum install -y parted 。 查看磁盘信息，发现磁盘 /dev/sdb 还没有分区123456789101112[root@hadoop-03 ~]# parted -lModel: VMware, VMware Virtual S (scsi)Disk /dev/sda: 21.5GBSector size (logical/physical): 512B/512BPartition Table: msdosNumber Start End Size Type File system Flags 1 1049kB 525MB 524MB primary ext4 boot 2 525MB 21.5GB 20.9GB primary lvmError: /dev/sdb: unrecognised disk label 开始分区12345678910111213141516171819202122[root@hadoop-03 ~]# parted /dev/sdbGNU Parted 2.1Using /dev/sdbWelcome to GNU Parted! Type 'help' to view a list of commands.(parted) mklabel gpt (parted) mkpart sdb1 File system type? [ext2]? xfs Start? 1 End? -1 (parted) p Model: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptNumber Start End Size File system Name Flags 1 1049kB 21.5GB 21.5GB sdb1(parted) quit Information: You may need to update /etc/fstab. [root@hadoop-03 ~]# 简单总结就是：12345678parted /dev/sdbmklabel gptmkpart sdb1xfs1-1pquit 每个命令的含义：12345678910111213141516171819202122Welcome to GNU Parted! Type 'help' to view a list of commands.(parted) help align-check TYPE N check partition N for TYPE(min|opt) alignment check NUMBER do a simple check on the file system cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER copy file system to another partition help [COMMAND] print general help, or help on COMMAND mklabel,mktable LABEL-TYPE create a new disklabel (partition table) mkfs NUMBER FS-TYPE make a FS-TYPE file system on partition NUMBER mkpart PART-TYPE [FS-TYPE] START END make a partition mkpartfs PART-TYPE FS-TYPE START END make a partition with a file system move NUMBER START END move partition NUMBER name NUMBER NAME name partition NUMBER as NAME print [devices|free|list,all|NUMBER] display the partition table, available devices, free space, all found partitions, or a particular partition quit exit program rescue START END rescue a lost partition near START and END resize NUMBER START END resize partition NUMBER and its file system rm NUMBER delete partition NUMBER select DEVICE choose the device to edit set NUMBER FLAG STATE change the FLAG on partition NUMBER toggle [NUMBER [FLAG]] toggle the state of FLAG on partition NUMBER unit UNIT set the default unit to UNIT version display the version number and copyright information of GNU Parted 然后再执行 parted -l 看到已经分区。1234567Model: VMware, VMware Virtual S (scsi)Disk /dev/sdb: 21.5GBSector size (logical/physical): 512B/512BPartition Table: gptNumber Start End Size File system Name Flags 1 1049kB 21.5GB 21.5GB sdb1 格式化分区以 xfs 文件系统为例：12# CentOS 低于 7.0 版本需安装 xfs 文件系统yum install -y xfsprogs xfsdump mkfs.xfs /dev/sdb1 或者 mkfs -t xfs /dev/sdb1 挂载到目录12mkdir -p /datamount /dev/sdb1 /data 设置开机自动挂载查看你要挂载的分区 UUID 及文件类型。123456[root@hadoop-03 ~]# blkid/dev/sda1: UUID="ecdab71d-a6eb-48fd-afa4-0a5dd3825795" TYPE="ext4" /dev/sda2: UUID="P4zVj0-zQrq-vJD5-7sWf-Oz2C-y3AK-da78ds" TYPE="LVM2_member" /dev/sdb1: UUID="fc9a9a29-c2f6-4286-bffd-dfba504359e3" TYPE="xfs" /dev/mapper/vg_hadoop03-lv_root: UUID="65522794-b23c-49f5-96ce-760091e399b8" TYPE="ext4" /dev/mapper/vg_hadoop03-lv_swap: UUID="ad1e0332-2242-478b-9bcf-184f837ebe76" TYPE="swap" 编辑系统分区表 /etc/fstab (使系统启动后自动挂载)，增加一条数据，修改 UUID 和文件类型：1UUID=fc9a9a29-c2f6-4286-bffd-dfba504359e3 /data xfs defaults 1 2 /etc/fstab 文件测试（重要）1mount -fav 若测试没有问题, 可以用1mount -av 来真的挂载所有的硬盘. 注意事项推荐 uuid 方式挂载。 错误挂载目录后在这两个文件删除相应内容即可/etc/fstab，/etc/mtab 常见问题ext4 格式化 16T 以上的分区，可以使用 e2fsprogs操作步骤： 123456789wget https://jaist.dl.sourceforge.net/project/e2fsprogs/e2fsprogs/v1.43.4/e2fsprogs-1.43.4.tar.gztar -zxvf e2fsprogs-1.43.4.tar.gz./configure --prefix=/home/e2fsprogsmake &amp;&amp; make install/home/e2fsprogs/mkfs.ext4 相关设备 然后挂载到目录，设置开机自动挂载]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>fdisk</tag>
        <tag>parted</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下except命令使用指南]]></title>
    <url>%2Fposts%2F2017%2F11%2F10%2FLinux%E4%B8%8Bexcept%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[安装Except：1yum -y install expect Expect中最关键的四个命令 send：用于向进程发送字符串 expect：从进程接收字符串 spawn：启动新的进程 interact：允许用户交互 Except脚本运行命令例一：12345678910111213141516#!/usr/bin/expectset timeout 5set user rootset ip 192.168.1.116set password simplespawn ssh $&#123;user&#125;@$&#123;ip&#125; -p 22expect &#123;"(yes/no)" &#123; send "yes\r"; exp_continue &#125;"password:" &#123; send "$password\r"; exp_continue &#125;"*#" &#123; send "ssh-keygen -t rsa &amp;&gt;/dev/null\n" &#125;"*#" &#123; send "ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop-0\n" &#125;"*#" &#123; send "exit\n" &#125;&#125;expect eof ; 注意第一行使用的是#!/usr/bin/expect而不是普通的bash脚本那样 expect都是使用{}，且{、}使用时，前后需要留空格 例子使用花括号，表示使用一组并列表达式，只要其中一项符合，就会执行该项，类似switchExcept脚本运行命令例二：1234#!/usr/bin/expectexpect "hi\n"send "you typed $expect_out(buffer)"send "but I only expected $expect_out(0,string)" 这两行代码的意思是：从标准输入中等到hi和换行键后，向标准输出输出hello there。 tips： $expect_out(buffer)存储了所有对expect的输入，&lt;$expect_out(0,string)&gt;存储了匹配到expect参数的输入。 12345expect &#123;"hi" &#123; send "You said hi\n"&#125;"hello" &#123; send "Hello yourself\n"&#125;"bye" &#123; send "That was unexpected\n"&#125;&#125; &lt;&lt;EOF：我们输入完成后，需要在一个新的一行输入EOF结束stdin的输入。EOF必须顶行写，前面不能用制表符或者空格&lt;&lt;-EOF：EOF前面的空格和制表符会被替换掉。 ${uaacconf//&quot;\r\n&quot;/ }把$uaacconf的所有换行替换为空格sed -ne &#39;/&#39;$HOST&#39;/=&#39; /etc/hosts 打印字符串匹配的行号&#39;awk &#39;{print $NF}&#39; 打印出一行中的最后一个字段&quot;$CONTAIN_NAME&quot;x = &quot;$name&quot;x 当变量为空会产生语法错误1&gt;/dev/null 2&gt;&amp;1 /dev/null 首先表示标准输出重定向到空设备文件，也就是不输出任何信息到终端，说白了就是不显示任何信息。 &amp;1 接着，标准错误输出重定向等同于标准输出，因为之前标准输出已经重定向到了空设备文件，所以标准错误输出也重定向到空设备文件。 /dev/null 代表空设备文件 代表重定向到哪里，例如：echo “123” &gt; /home/123.txt1 表示stdout标准输出，系统默认值是1，所以”&gt;/dev/null”等同于”1&gt;/dev/null”2 表示stderr标准错误&amp; 表示等同于的意思，2&gt;&amp;1，表示2的输出重定向等同于1]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机（Vmware）桥接模式CentOS 6系统下使用静态IP上外网配置指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F22%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88Vmware%EF%BC%89%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81IP%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[Vmware设置打开Vmware，单击 【编辑】 -&gt; 【虚拟网络编辑器】。然后点击 【更改设置】，选中VMnet0，在VMnet信息里选择【桥接模式】，桥接到你上网用的网卡。我电脑连的WiFi，所以选择Qualcomm Atheros AR9485 Wireless Network Adapter无线网卡。 虚拟机设置打开虚拟机界面，单击【编辑虚拟机设置】，点击左侧【网络适配器】，选择【桥接模式】（复制物理网络连接状态我没选过，不知道选了怎样），或者 【自定义】 –&gt; VMnet0。 CentOS系统网卡设置静态IP地址首先查看物理主机ip地址，我连接的是无线网，信息如下：1234567无线局域网适配器 WLAN: 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : fe80::796c:6c41:254c:b8b4%12 IPv4 地址 . . . . . . . . . . . . : 192.168.0.105 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : 192.168.0.1 然后进行设置Linux系统的静态IP地址，CentOS文件路径是 /etc/sysconfig/network-scripts/ifcfg-eth0，修改ONBOOT为yes，BOOTPROTO为static，然后添加四行，值根据实际情况修改。1234IPADDR=192.168.0.108NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=8.8.8.8 IPADDR确保和物理主机ip地址在同一网段，ping一下确保是没有使用的后可以随意设置。 NETMASK子网掩码和物理主机子网掩码相同 GATEWAY默认网关和物理主机默认网关相同 DNS1设置为8.8.8.8。 修改后文件示例如下1234567891011DEVICE=eth0HWADDR=00:0C:29:F6:7C:EETYPE=EthernetUUID=b1646521-c808-411a-840d-b4a52a458340ONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.0.108NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=8.8.8.8 最后重启网卡应该就可以上外网了service network restart。 常见问题重启网卡提示 Active connection path: /org/freedesktop/NetworkManager/ActiveConnection/23此时，当前网卡也是可以通信的，但是通过网络管理工具修改IP之后，当前修改操作是不会生效的。那如何消除这个提示呢？ 其实，问题的原因是 RedHat 自己开发的 NetworkManager 管理工具和 /etc/sysconfig/network-scripts/ifcfg-ethx 配置不同步造成的。如果要消除这个提示，请关闭 NetworkManager 服务即可： 123[root@vdb1 dev]# chkconfig NetworkManager off --永久关闭服务，需要重启[root@vdb1 dev]# service NetworkManager stop --立即关闭服务，不需要重启Stopping NetworkManager daemon: [ OK ] 此时，再重新加载network服务即可：123456[root@cdh1 yum.repos.d]# service network restartShutting down interface eth0: [ OK ]Shutting down loopback interface: [ OK ]Bringing up loopback interface: [ OK ]Bringing up interface eth0: Determining if ip address 192.168.1.110 is already in use for device eth0... [ OK ]]]></content>
      <categories>
        <category>虚拟机</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7minimal在VMware上的安装指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F22%2FCentOS7minimal%E5%9C%A8VMware%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[从ustc下载安装包 1. 修改网卡名称为eth0从CentOS/RHEL7起，可预见的命名规则变成了默认。这一规则，接口名称被自动基于固件，拓扑结构和位置信息来确定。出于习惯等一些原因，修改为熟悉的eth0. 编辑/etc/sysconfig/network-scripts/ifcfg-eno16777736可能是ifcfg-xxxx，将里面的NAME修改为eth0 重名名该文件为mv ifcfg-eno16777736 ifcfg-eth0 然后，禁用该可预测命名规则，向/etc/default/grub文件的GRUB_CMDLINE_LINUX变量追加：net.ifnames=0 biosdevname=0 运行命令grub2-mkconfig -o /boot/grub2/grub.cfg 来重新生成GRUB配置并更新内核参数 第4步重启就已经生效了，根据Centos 官方WIKI的FAQ中得知，如果你有多个接口，并且想要控制其设备名，而不是让内核以它自己的方式命名，创建/etc/udev/rules.d/XXX-net.rules规则是必要的！那么这里我们也创建好规则吧。以前系统的net规则名称是70-persistent-net.rules，这里我也按照这个名字定义规则！编辑文件添加下面一行。更换成你自己的MAC地址（08:00:27:a9:7a:e1）和接口（eth0）。 12vi /etc/udev/rules.d/70-persistent-net.rulesSUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:0c:29:6d:06:88", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth0" 重启系统，验证！ 如果Centos7系统minimal方式安装是没有ifconfig命令的，可以通过安装yum install net-tools解决。 备注：linux中查看网卡mac地址 ip ether后面的字段就是mac地址 ifconfig -a 其中 HWaddr字段就是mac地址 cat /sys/class/net/eth0/address 查看eth0的mac地址 cat /proc/net/arp 查看连接到本机的远端ip的mac地址 修改/etc/sysconfig/network-script/ifcfg-eth0:(注意：设置vmware为net共享模式) HWADDR=”00:0c:29:6d:06:88”iIPADDR=”192.168.11.103”NETMASK=”255.255.255.0”GATEWAY=”192.168.11.2”DNS1=8.8.8.8 2. 设置基础环境更新yum源安装ifconfig yum -y install net-tools安装其他 yum -y install gcc gcc-c++ vim dos2unix ntpdate openssh-clients]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL5.7在CentOS7上的安装指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F19%2FMySQL5-7%E5%9C%A8CentOS7%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[1、配置YUM源在MySQL官网中下载YUM源rpm安装包：http://dev.mysql.com/downloads/repo/yum/1234# 下载mysql源安装包shell&gt; wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm# 安装mysql源shell&gt; yum localinstall mysql57-community-release-el7-8.noarch.rpm 检查mysql源是否安装成功 1234[root@iZsqo0q6xrrbl8Z etc]# yum repolist enabled | grep "mysql.*-community.*"mysql-connectors-community/x86_64 MySQL Connectors Community 30mysql-tools-community/x86_64 MySQL Tools Community 40mysql57-community/x86_64 MySQL 5.7 Community Server 164 看到上图所示表示安装成功 2、安装MySQL1shell&gt; yum install mysql-community-server 3. 启动MySql服务1shell&gt; systemctl start mysqld 查看MySql的启动状态12345678910shell&gt; systemctl status mysqld● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; disabled; vendor preset: disabled) Active: active (running) since 五 2016-06-24 04:37:37 CST; 35min ago Main PID: 2888 (mysqld) CGroup: /system.slice/mysqld.service └─2888 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid6月 24 04:37:36 localhost.localdomain systemd[1]: Starting MySQL Server...6月 24 04:37:37 localhost.localdomain systemd[1]: Started MySQL Server. 4. 开机启动12shell&gt; systemctl enable mysqldshell&gt; systemctl daemon-reload 5、修改root默认密码mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个默认密码。通过下面的方式找到root默认密码，然后登录mysql进行修改1shell&gt; grep 'temporary password' /var/log/mysqld.log 12shell&gt; mysql -uroot -pmysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!'; 注意：mysql5.7默认安装了密码安全检查插件（validate_password），默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位。否则会提示ERROR 1819 (HY000): Your password does not satisfy the current policy requirements错误，如下图所示 如果不需要密码策略，添加my.cnf文件中添加如下配置禁用即可：1validate_password = off 重新启动mysql服务使配置生效：1systemctl restart mysqld 6、添加远程登录用户默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须修改root允许远程连接，或者添加一个允许远程连接的帐户，为了安全起见，我添加一个新的帐户：123grant all privileges on 数据库名.表名 to 创建的用户名 @"%" identified by "密码"; /* 数据库名.表名 如果写成*.*代表授权所有的数据库 */flush privileges; /* 刷新刚才的内容*/ 12345678910111213mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select host,user from user;+-----------+-----------+| host | user |+-----------+-----------+| localhost | mysql.sys || localhost | root |+-----------+-----------+2 rows in set (0.00 sec) 默认root用户只能在本地登录 123456789101112131415161718mysql&gt; grant all privileges on *.* to blue @"%" identified by "justdoit";Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges; /* 刷新刚才的内容*/ Query OK, 0 rows affected (0.00 sec)mysql&gt; select host,user from user;+-----------+-----------+| host | user |+-----------+-----------+| % | blue || localhost | mysql.sys || localhost | root |+-----------+-----------+3 rows in set (0.00 sec)mysql&gt; 添加blue远程登录用户 同时也可以为现有的用户设置是否具有远程访问权限。如下： 12345use mysql;update db set host = '%' where user = '用户名'; /*（如果写成 host=localhost 那此用户就不具有远程访问权限）*/FLUSH PRIVILEGES; 7、配置默认编码为utf8修改/etc/my.cnf配置文件，在[mysqld]下添加编码配置，如下所示： 123[mysqld]character_set_server=utf8init_connect='SET NAMES utf8' 重新启动mysql服务，查看数据库默认编码如下所示： 1234567891011121314mysql&gt; show variables like '%character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 默认配置文件路径： 配置文件：/etc/my.cnf 日志文件：/var/log//var/log/mysqld.log 服务启动脚本：/usr/lib/systemd/system/mysqld.service socket文件：/var/run/mysqld/mysqld.pid 卸载]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVNServer在CentOS6.7上的部署指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F12%2FSVNServer%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[一般来说，subversion服务器可以用两种方式架设： 一种是基于svnserve，svnserve作为服务端 一种是基于Apache，用apache作为服务端 这里以svnserver为例 安装svnserver docker安装 1docker pull garethflowers/svn-server 本地安装 1234[root@localhost ~]# yum -y install subversion[root@localhost ~]# svnserve --versionsvnserve, version 1.7.14 (r1542130) compiled Nov 20 2015, 19:25:09 配置svnserver1. 添加svn管理用户和subversion组（这步很重要，不然会导致authentication failed）12345678910# centos下：sudo adduser svnuser #(添加svnuser用户）sudo groupadd subversion #（添加subversion组）sudo groupadd -G subversion svnuser sudo groupadd -G root subversion #把root用户添加到组里# Ubuntu下：sudo adduser svnuser #(添加svnuser用户）sudo addgroup subversion #（添加subversion组）sudo addgroup svnuser subversion sudo addgroup root subversion #把root用户添加到组里 2. 开始创建项目目录12345mkdir /home/svn #(这里的svn即为版本库目录文件，以后所有的操作都在/home/svn下cd /home/svnmkdir repo #(这里即为一个版本库文件，文件名可以任意取）chown -R root:subversion repochmod -R g+rws repo 3. 创建SVN文件仓库，即为上面建立的repo文件目录1svnadmin create /home/svn/repo 到这一步，安装基本完成，开始改配置。 4. 在/home/svn/repo文件目录中可以看到conf文件夹，可针对conf文件夹中的authz、passwd、svnserve.conf进行设置，svnserve.conf主要设置整体的安全策略，passwd则设置用户名和密码， authz 则是设置具体的用户有什么权限。5. 访问权限设置 编辑svnserve.conf文件 anon-access：匿名用户的权限，可以为read，write和none，默认值read。不允许匿名用户访问：anon-access = none auth-access：认证用户的权限，可以为read，write和none，默认值write。 password-db：密码数据库的路径，去掉前边的# authz-db：认证规则库的路径，去掉前边的# 这些配置项的行都要顶格，否则会报错。修改配置后需要重启svn才能生效。 编辑passwd文件，加入用户名和密码 用户名=密码, 采用的是明码。如allen=1（apache模式下密码为经过加密的变化） 如下： 12[users]slhan=justdoit 编辑authz文件，配置用户访问权限（如下为示例） [groups]设置，为了便于管理，可以将一些用户放到一个组里边，比如：owner=allen,ellen,如下： 1234[groups]# harry_and_sally = harry,sally# harry_sally_and_joe = harry,sally,&amp;joeowner=slhan groups下边的配置表示对一个目录的认证规则，比如对根目录的认证规则的section为[/]。设置单用户的认证规则时一个用户一行，如： 123[/]allen=rw #allen对根目录的权限为rwellen=r #ellen对根目录的权限为r 如果使用group，需要在group名字前加@,如 1@owner=rw 每个仓库的根目录(/)就是自己的起始目录；[repos:/]这种方式只适用于多仓库的情况；[/]适合于单仓库和单仓库的方式。更多关于单仓库和多仓库的问题， 6. 启动svn服务svnserve -d -T -r /home/svn描述说明： -d 表示svnserver以“守护”进程模式运行 -T 表示以线程模式运行，增加效率 -r 指定文件系统的根位置（版本库的根目录），这样客户端不用输入全路径，就可以访问版本库。如: svn://你的IP/repo部署验证使用客户端访问svn://你的IP/repo 注意authz passwd svnserve.conf文件所有行的前面都不能有空格注意建立svn管理用户和组]]></content>
      <categories>
        <category>Linux</category>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ApacheHTTPServer2.4.25在CentOS6.7上的部署手册]]></title>
    <url>%2Fposts%2F2017%2F10%2F12%2FApacheHTTPServer2-4-25%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[前言依赖于gcc、gcc-c++、APR、APR-Util、PCRE(pcre而不是pcre2，pcre2后面出错) 安装流程安装gcc编译器1yum install -y gcc gcc-c++ 安装APR，放到/var/local目录下，解压：1tar -zxvf apr-1.5.2.tar.gz 接着进行安装步骤了，进入到解压的目录下执行如下命令123./configure --prefix=/usr/local/apr/ （设置apr安装目录，这里的 /usr/local/apr/ 才是apr真正的安装目录）makemake install 安装apr-util到网上卸载apr-util-1.5.1.tar.gz。再次解压缩。。。和上面的一样，不过它的安装需要依赖于apr，1234./configure --prefix=/usr/local/apr-util/ --with-apr=/usr/local/apr/ make make install 安装pcre，同aprapache安装添加依赖于apr, apr-util, pcre 启动1/usr/local/apache/bin/apachectl start]]></content>
      <categories>
        <category>中间件</category>
        <category>负载均衡</category>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx1.11.9在CentOS6.7上的部署指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F12%2Fnginx1-11-9%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[安装流程安装 PCRE，然后安装 nginx。 安装PCRE1yum -y install pcre-devel 下载 nginx-1.11.9.tar.gz 安装包放到 /usr/local 目录下，解压：1tar -zxvf nginx-1.11.9.tar.gz 接着进行安装步骤了，进入到解压的目录下执行如下命令12345678910111213141516171819./configurenginx path prefix: "/usr/local/nginx"nginx binary file: "/usr/local/nginx/sbin/nginx"# 注意binary file为启动nginx时的路径。nginx modules path: "/usr/local/nginx/modules"nginx configuration prefix: "/usr/local/nginx/conf"nginx configuration file: "/usr/local/nginx/conf/nginx.conf"nginx pid file: "/usr/local/nginx/logs/nginx.pid"nginx error log file: "/usr/local/nginx/logs/error.log"nginx http access log file: "/usr/local/nginx/logs/access.log"nginx http client request body temporary files: "client_body_temp"nginx http proxy temporary files: "proxy_temp"nginx http fastcgi temporary files: "fastcgi_temp"nginx http uwsgi temporary files: "uwsgi_temp"nginx http scgi temporary files: "scgi_temp"makemake install 启动1/usr/local/nginx/sbin/nginx 停止1/usr/local/nginx/sbin/nginx -s stop 从容停止1kill - QUIT nginx 主进程号 停止nginx所有进程1pkill -9 nginx 部署验证在浏览器中输入IP：端口号，看到 Welcome to nginx!页面，表示安装成功。 常见问题]]></content>
      <categories>
        <category>中间件</category>
        <category>负载均衡</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Registry HTTP API V2]]></title>
    <url>%2Fposts%2F2017%2F10%2F12%2FDockerRegistryHTTPAPIV2%2F</url>
    <content type="text"><![CDATA[Docker Registry V2版本的官方HTTP API method path Entity Description GET /v2/ Base Check that the endpoint implements Docker Registry API V2. GET /v2/&lt;name&gt;/tags/list Tags Fetch the tags under the repository identified by name. GET /v2/&lt;name&gt;/manifests/&lt;reference&gt; Manifest Fetch the manifest identified by name and reference where reference can be a tag or digest. A HEADrequest can also be issued to this endpoint to obtain resource information without receiving all data. PUT /v2/&lt;name&gt;/manifests/&lt;reference&gt; Manifest Put the manifest identified by name and reference where reference can be a tag or digest. DELETE /v2/&lt;name&gt;/manifests/&lt;reference&gt; Manifest Delete the manifest identified by name and reference. Note that a manifest can only be deleted by digest. GET /v2/&lt;name&gt;/blobs/&lt;digest&gt; Blob Retrieve the blob from the registry identified bydigest. A HEADrequest can also be issued to this endpoint to obtain resource information without receiving all data. DELETE /v2/&lt;name&gt;/blobs/&lt;digest&gt; Blob Delete the blob identified by name and digest POST /v2/&lt;name&gt;/blobs/uploads/ Initiate Blob Upload Initiate a resumable blob upload. If successful, an upload location will be provided to complete the upload. Optionally, if thedigest parameter is present, the request body will be used to complete the upload in a single request. GET /v2/&lt;name&gt;/blobs/uploads/&lt;uuid&gt; Blob Upload Retrieve status of upload identified byuuid. The primary purpose of this endpoint is to resolve the current status of a resumable upload. PATCH /v2/&lt;name&gt;/blobs/uploads/&lt;uuid&gt; Blob Upload Upload a chunk of data for the specified upload. PUT /v2/&lt;name&gt;/blobs/uploads/&lt;uuid&gt; Blob Upload Complete the upload specified by uuid, optionally appending the body as the final chunk. DELETE /v2/&lt;name&gt;/blobs/uploads/&lt;uuid&gt; Blob Upload Cancel outstanding upload processes, releasing associated resources. If this is not called, the unfinished uploads will eventually timeout. GET /v2/_catalog Catalog Retrieve a sorted, json list of repositories available in the registry.]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker1.7.1 在 CentosOS6.7 上安装指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F12%2FDocker1-7-1%E5%9C%A8CentosOS6-7%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[安装包 kernel-lt-devel-3.10.104-1.el6.elrepo.x86_64.rpm libcgroup-0.40.rc1-23.el6.x86_64.rpm docker-engine-1.7.1-1.el6.x86_64.rpm 安装流程安装新版本内核注意：V4 CPU安装新版本内核有问题，不要安装，查看 CPU 型号命令如下，看到 V4 不要安装。12[root@docker1 ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 32 Intel(R) Xeon(R) CPU E5-2620 V4 @ 2.10GHz 安装1rpm -ivh kernel-lt-devel-3.10.104-1.el6.elrepo.x86_64.rpm 将新内核作为默认启动的内核，编辑内核配置文件 /boot/grub/grub.conf，将默认的 default=1 修改为 0。 /boot/grub/grub.conf 配置文件解析 12default=0 # 表示第一个 title 下的内容为默认启动的 kernel 安装 cgroups,docker 依赖项1rpm -ivh libcgroup-0.40.rc1-23.el6.x86_64.rpm 安装 docker 1.7.11rpm -ivh docker-engine-1.7.1-1.el6.x86_64.rpm 修改 Docker 配置文件 /etc/sysconfig/docker,主要为 Docker 仓库和 4243 服务端口外放 --insecure-registry后面是私人仓库地址，根据实际修改 --graph 指定 Docker 默认存放路径 下面是栗子：1other_args="-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock --graph=/var/lib/docker --insecure-registry 192.168.1.100:5000" 启动system docker start，查看版本信息：12[root@docker1 ~]# docker -vDocker version 1.7.1, build 786b29d 常见问题运行容器报错：Error response from daemon: Error running DeviceCreate (createSnapDevice) dm_task_run failedmetadata目录在docker info查看1234service docker stopthin_check /var/lib/docker/devicemapper/devicemapper/metadatathin_check --clear-needs-check-flag /var/lib/docker/devicemapper/devicemapper/metadataservice docker start Error running DeviceCreate (ActivateDevice) dm_task_run failed重启docker服务器后 遇到 ‘device or resource busy’错误如果有container在运行的时候重启 docker 服务， 可能会导致 container无法启动， 错误信息类似于12Error response from daemon: Cannot start container zookeeper: Error getting container ddf1dd91bbf46dc648268327f8f7c6fffaf2f19cda5cf1d97fdc701016d4332c from driver devicemapper: Error mounting '/dev/mapper/docker-8:1-525372-ddf1dd91bbf46dc648268327f8f7c6fffaf2f19cda5cf1d97fdc701016d4332c' on '/var/lib/docker/devicemapper/mnt/ddf1dd91bbf46dc648268327f8f7c6fffaf2f19cda5cf1d97fdc701016d4332c': device or resource busy 2015/01/26 04:42:07 Error: failed to start one or more containers 或者12d2859bd1f84b: Error pulling image (latest) from xxxxxx, Driver devicemapper failed to create image rootfs e6158e7962db43274de40fc3db65ad64811d43fe342dea633df20639f5a4e3cd: device e6158e7962db43274de40fc3db65ad64811d43fe342dea633df20639f5a4e3cd already exists 43fe342dea633df20639f5a4e3cd already exists c049b2b: Download complete e6158e7962db: Error downloading dependent layers 这是一个Docker的 bug ，解决方式是先找出没有umount的路径1cat /proc/mounts | grep "mapper/docker" | awk '&#123;print $2&#125;' 然后依次umount [8] System error: fork/exec /usr/bin/docker: cannot allocate memory问题The fix for me was to add swapspace. By default my digitalocean droplet didn’t come with any swap!1234dd if=/dev/zero of=/root/myswapfile bs=1M count=1024chmod 600 /root/myswapfilemkswap -f /root/myswapfileswapon /root/myswapfile]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH免密码登录在CentOS6.7上的配置指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F12%2FSSH%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[前言我用的是root用户，每台服务器都生成公钥，合并到authorized_keys后，分发到集群内各节点 。 生成公钥/私钥每台机器上运行1ssh-keygen -t rsa -P '' 收集所有公钥写入authorized_keys 分别复件docker2 docker3密钥文件到docker1 12scp /root/.ssh/id_rsa.pub docker1:/root/.ssh/docker2_id_rsa.pub // docker2 机器上执行scp /root/.ssh/id_rsa.pub docker1:/root/.ssh/docker3_id_rsa.pub // docker3 机器上执行 查看docker1上， 已复制的文件 12345678910[root@docker1 ~]# ls -al ~/.ssh/total 32drwxr-xr-x 2 root root 4096 May 12 10:28 .dr-xr-x---. 3 root root 4096 May 12 10:22 ..-rw-r--r-- 1 root root 2364 May 12 10:28 authorized_keys-rw-r--r-- 1 root root 394 May 12 10:28 cdh2_id_rsa.pub-rw-r--r-- 1 root root 394 May 12 10:27 cdh3_id_rsa.pub-rw------- 1 root root 1675 May 12 10:22 id_rsa-rw-r--r-- 1 root root 394 May 12 10:22 id_rsa.pub-rw-r--r-- 1 root root 1596 May 12 10:15 known_hosts 之前拷贝的名字为cdh2_id_rsa.pub、cdh3_id_rsa.pub 将复制来的密钥添加到docker1上的authorized_keys 123cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keyscat /root/.ssh/docker2_id_rsa.pub &gt;&gt; /root/.ssh/authorized_keyscat /root/.ssh/docker3_id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys 分发authorized_keys到集群内节点将docker1上的authorized_keys文件， 分发到集群内其它机器12scp /root/.ssh/authorized_keys docker2:/root/.ssh/authorized_keysscp /root/.ssh/authorized_keys docker3:/root/.ssh/authorized_keys 配置验证12345[root@docker1 ~]# ssh docker2Last login: Fri May 12 10:57:04 2017 from 192.168.75.11[root@docker2 ~]# ssh docker1Last login: Fri May 12 10:56:30 2017 from 192.168.75.11[root@docker1 ~]# 常见问题SSH互信配置完成，仍然要输入密码原因分析 .ssh目录的权限必须是700，同时本机的私钥的权限必须设置成600： /root目录权限不对,要设置为755，/root的用户和用户组必须为root 查看日志/var/log/secureRSA host key for cdh2 has changed and you have requested strict checking.Host key verification failed. 1234567891011121314151617181920212223[root@cdh1 cdh]# scp oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm cdh2:/root/@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: POSSIBLE DNS SPOOFING DETECTED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@The RSA host key for cdh2 has changed,and the key for the corresponding IP address 192.168.1.111is unknown. This could either mean thatDNS SPOOFING is happening or the IP address for the hostand its host key have changed at the same time.@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that the RSA host key has just been changed.The fingerprint for the RSA key sent by the remote host ise4:4d:8b:f4:91:2e:54:be:12:97:a2:f5:d9:67:0d:6b.Please contact your system administrator.Add correct host key in /root/.ssh/known_hosts to get rid of this message.Offending key in /root/.ssh/known_hosts:2RSA host key for cdh2 has changed and you have requested strict checking.Host key verification failed.lost connection 在 .ssh 目录下有一个 known_hosts 文件 把这个文件删除或者改名 即可]]></content>
      <categories>
        <category>Linux</category>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived1.2.13在CentOS6.7上的部署指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F09%2Fkeepalived1-2-13%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[解压安装1234567tar -zxvf keepalived-1.2.13.tar.gzcd keepalived-1.2.13#安装依赖yum install –y openssl openssl-devel#配置、编译安装./configure --disable-fwmarkmake &amp;&amp; make install 开机服务启动1234cp /usr/local/etc/rc.d/init.d/keepalived /etc/init.d/cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/ #启动初始化mkdir -p /etc/keepalived/cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/ 注：确保拷贝的路径存在（/etc/keepalived/可能会不存在，不存在首先创建） 123cp /usr/local/sbin/keepalived /usr/sbin/ #启动文件chkconfig --add keepalivedchkconfig --level 2345 keepalived on 设置Nginx等监控脚本（在与Nginx绑定时需要）为了防止Keepalived节点上nginx等程序终止，但Keepalived服务正常导致IP无法漂移，需要增加监控脚本，对这些依赖的进程进行监控 创建监控脚本 1234567891011[root@localhost ~]# vim /etc/keepalived/nginx_pid.sh#!/bin/bash# count=`netstat -tln | grep 80 | grep -v 'grep' | grep -v '/bin/bash' | grep -v '[0-9]+80[0-9]+' | wc -l`count=`ps aux | grep nginx | grep -v grep | grep -v '/bin/bash' | wc -l`echo "Nginx process number:"$countif [ $count -gt 0 ]; then exit 0;else service keepalived stop exit 1;fi 为启动脚本授权 1chmod 755 /etc/keepalived/nginx_pid.sh 配置keepalived权重及脚本调用 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@localhost ~]# vi /etc/keepalived/keepalived.confglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL&#125; vrrp_script checknginx &#123; script "/etc/keepalived/nginx_pid.sh" interval 3 weight -20 &#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 priority 80 nopreemp advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; checknginx &#125; track_interface &#123; eth0 &#125; virtual_ipaddress &#123; 192.168.32.81 &#125;&#125; 检测脚本可以自定义规则，比如：curl ip地址，检测80端口是否被占用等。 其他进程监控 可增加多个check。 启动|停止配置1service keepalived start | stop | restart 开启日志keepalived默认不开启日志，需要修改配置文件开启日志1234#centosvim /etc/sysconfig/keepalived#ubuntuvim /etc/default/keepalived 改成：KEEPALIVED_OPTIONS=&quot;-D -d -S 0&quot;12vim /etc/rsyslog.conf#如果没有/etc/rsyslog.conf文件，使用yum安装yum install rsyslog 最后一行追加：1local0.* /var/log/keepalived.log 最后重启12service rsyslog restartservice keepalived restart 常见问题日志报one or more VIP associated with VRID mismatch actual MASTER advert是同一网段部署了多个keepalived集群，导致virtual_router_id值冲突了，均使用了默认的值：51，修改其中一个virtual_router_id值（取值范围1~255）为88（新数字就可以）解决 keepalived日志报错狂刷：IPVS: Can’t initialize ipvs: Protocol not available原因是ip_vs模块系统默认没有自动加载，可以通过lsmod | grep ip_vs 命令查看一下，如果没有任何输出则表示ip_vs模块并没有被内核加载，那必须手动加载一下：12modprobe ip_vsmodprobe ip_vs_wrr 然后再查看系统日志发现keepalived已经正常工作了。如果要让系统开机加载此模块的话得讲刚才那两句话写到/etc/rc.local文件中，这样开机就能自动加载了。有时候会报错 报错IPVS: Can’t initialize ipvs: Permission denied (you must be root)使用root用户。若使用容器在container运行时加上--privileged=true]]></content>
      <categories>
        <category>中间件</category>
        <category>高可用</category>
        <category>Keepalived</category>
      </categories>
      <tags>
        <tag>Keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDBCommunityEdition在CentOS6.7上的部署指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F09%2FMongoDBCommunityEdition%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[install mongodbConfigure the package management system (yum).Create a /etc/yum.repos.d/mongodb-org-3.4.repo file so that you can install MongoDB directly, using yum. For the latest stable release of MongoDBUse the following repository file:123456[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc You can find .repo files for each release in the repository itself. Remember that odd-numbered minor release versions (e.g. 2.5) are development versions and are unsuitable for production use. Install the MongoDB packages and associated tools.1yum install -y mongodb-org Run MongoDB Community EditionConfigure SELinux If you are using SELinux, you must configure SELinux to allow MongoDB to start on Red Hat Linux-based systemsTo configure SELinux, administrators have three options: If SELinux is in enforcing mode, enable access to the relevant ports that the MongoDB deployment will use (e.g. 27017). For default settings, this can be accomplished by running: 1semanage port -a -t mongod_port_t -p tcp 27017 Disable SELinux by setting the SELINUX setting to disabled in /etc/selinux/config. 1SELINUX=disabled You must reboot the system for the changes to take effect. Set SELinux to permissive mode in /etc/selinux/config by setting the SELINUX setting to permissive. You must reboot the system for the changes to take effect. Data Directories and PermissionsThe MongoDB instance stores its data files in /var/lib/mongo and its log files in /var/log/mongodb by default, and runs using the mongod user account. You can specify alternate log and data file directories in /etc/mongod.conf. ProcedureStart MongoDB.1sudo service mongod start Verify that MongoDB has started successfullyYou can verify that the mongod process has started successfully by checking the contents of the log file at /var/log/mongodb/mongod.log for a line reading [initandlisten] waiting for connections on port where &lt;port&gt; is the port configured in /etc/mongod.conf, 27017 by default. You can optionally ensure that MongoDB will start following a system reboot by issuing the following command:1sudo chkconfig mongod on Stop MongoDB1sudo service mongod stop restart MongoDB1sudo service mongod restrat Uninstall MongoDB Community Edition1234sudo service mongod stopsudo yum erase $(rpm -qa | grep mongodb-org)sudo rm -r /var/log/mongodbsudo rm -r /var/lib/mongo]]></content>
      <categories>
        <category>数据库</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat7.0.79镜像定制说明]]></title>
    <url>%2Fposts%2F2017%2F10%2F09%2Ftomcat7-0-79%E9%95%9C%E5%83%8F%E5%AE%9A%E5%88%B6%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[一、 设置session共享，可使用memcached或Redis（实际部署只能使用其中一个），下面详细介绍：use memcached session share（这里使用kryo 策略） 1. 添加jar包到tomcat的lib目录下支持memcache共享： asm-5.0.3.jar kryo-3.0.3.jar kryo-serializers-0.37.jar memcached-session-manager-1.9.5.jar memcached-session-manager-tc7-1.9.5.jar minlog-1.3.0.jar msm-kryo-serializer-1.9.5.jar objenesis-2.1.jar reflectasm-1.10.1.jar spymemcached-2.12.0.jar2. 添加下面的配置文件到content.xml中12345678&lt;Manager transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory" sessionBackupTimeout="180000" sessionBackupAsync="false" requestUriIgnorePattern=".*\.(png|gif|jpg|css|js)$" lockingMode="auto" sticky="false" memcachedNodes="n1:172.31.1.73:11211" className="de.javakaffee.web.msm.MemcachedBackupSessionManager"/&gt; 3. Reboot the server, and sessions should now be stored in Memcached.use redis session share1. 添加jar包到tomcat的lib目录下支持redis共享： commons-pool-2.2.2.jar jedis-2.5.2.jar tomcat-redis-session-manager-1.2-tomcat-7.jar2. 添加下面的配置文件到content.xml中123456&lt;Valve className="com.radiadesign.catalina.session.RedisSessionHandlerValve" /&gt; &lt;Manager className="com.radiadesign.catalina.session.RedisSessionManager" host="172.31.1.73"&lt;!-- optional: defaults to "localhost" --&gt; port="6379"&lt;!-- optional: defaults to "6379" --&gt; database="0"&lt;!-- optional: defaults to "0" --&gt; maxInactiveInterval="60"&lt;!-- optional: defaults to "60" (in seconds) --&gt;/&gt; 3. Reboot the server, and sessions should now be stored in Redis.测试session共享是否成功访问http://tomcatip:port/sesstest.jsp，观察sessionid是否有变化 二、 使用log4j作为默认日志 拷贝log4j-1.2.11.jar、tomcat-juli-adapters.jar、log4j.properties到%TOMCAT_HOME%/lib/目录 拷贝tomcat-juli.jar到%TOMCAT_HOME%/bin/目录 删除%TOMCAT_HOME%/conf/logging.properties jar包下载地址见(这是tomcat6):https://tomcat.apache.org/tomcat-6.0-doc/logging.html#Using_Log4j 我的log4j.properties文件如下,这样设为按照大小分割,每5MB分割，最多分割为30个文件，超过了循环覆盖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849log4j.rootLogger=INFO, CATALINA# Define all the appenderslog4j.appender.CATALINA=org.apache.log4j.RollingFileAppenderlog4j.appender.CATALINA.File=$&#123;catalina.home&#125;/logs/catalina.outlog4j.appender.CATALINA.Append=truelog4j.appender.CATALINA.Encoding=UTF-8log4j.appender.CATALINA.layout=org.apache.log4j.PatternLayoutlog4j.appender.CATALINA.layout.ConversionPattern=%d&#123;yyyy.MM.dd HH:mm:ss&#125; %p-%c&#123;1&#125;: [%m]%nlog4j.appender.CATALINA.MaxFileSize=5MBlog4j.appender.CATALINA.MaxBackupIndex=30# Roll-over the log by sizelog4j.appender.LOCALHOST=org.apache.log4j.RollingFileAppenderlog4j.appender.LOCALHOST.File=$&#123;catalina.home&#125;/logs/localhost.loglog4j.appender.LOCALHOST.Append=truelog4j.appender.LOCALHOST.Encoding=UTF-8log4j.appender.LOCALHOST.layout=org.apache.log4j.PatternLayoutlog4j.appender.LOCALHOST.layout.ConversionPattern=%d&#123;yyyy.MM.dd HH:mm:ss&#125; %p-%c&#123;1&#125;: [%m]%nlog4j.appender.LOCALHOST.MaxFileSize=5MBlog4j.appender.LOCALHOST.MaxBackupIndex=30log4j.appender.MANAGER=org.apache.log4j.RollingFileAppenderlog4j.appender.MANAGER.File=$&#123;catalina.home&#125;/logs/manager.loglog4j.appender.MANAGER.Append=truelog4j.appender.MANAGER.Encoding=UTF-8log4j.appender.MANAGER.layout=org.apache.log4j.PatternLayoutlog4j.appender.MANAGER.layout.ConversionPattern=%d&#123;yyyy.MM.dd HH:mm:ss&#125; %p-%c&#123;1&#125;: [%m]%nlog4j.appender.MANAGER.MaxFileSize=5MBlog4j.appender.MANAGER.MaxBackupIndex=30log4j.appender.HOST-MANAGER=org.apache.log4j.RollingFileAppenderlog4j.appender.HOST-MANAGER.File=$&#123;catalina.home&#125;/logs/host-manager.loglog4j.appender.HOST-MANAGER.Append=truelog4j.appender.HOST-MANAGER.Encoding=UTF-8log4j.appender.HOST-MANAGER.layout=org.apache.log4j.PatternLayoutlog4j.appender.HOST-MANAGER.layout.ConversionPattern=%d&#123;yyyy.MM.dd HH:mm:ss&#125; %p-%c&#123;1&#125;: [%m]%nlog4j.appender.HOST-MANAGER.MaxFileSize=5MBlog4j.appender.HOST-MANAGER.MaxBackupIndex=30log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Encoding=UTF-8log4j.appender.CONSOLE.layout = org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern = %d [%t] %-30p %c- %m%n# Configure which loggers log to which appenderslog4j.logger.org.apache.catalina.core.ContainerBase.[Catalina].[localhost]=INFO, LOCALHOSTlog4j.logger.org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager]=INFO, MANAGERlog4j.logger.org.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager]=INFO, HOST-MANAGER]]></content>
      <categories>
        <category>中间件</category>
        <category>应用服务器</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTP在CentOS6.7上的安装指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F09%2FNTP%E5%9C%A8CentOS6-7%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[使用root用户进行操作，涉及所有服务器。 设置所有服务器在同一时区123TZ=Asia/Shanghailn -snf /usr/share/zoneinfo/$TZ /etc/localtimeecho $TZ &gt; /etc/timezone 安装ntp服务 查看是否已经安装：rpm -qa | grep ntp。 如果已安装就不需要再安装了。123[root@docker2 ~]# rpm -qa | grep ntpntpdate-4.2.6p5-5.el6.centos.x86_64ntp-4.2.6p5-5.el6.centos.x86_64 如果没安装，使用： yum install ntpd 安装设置开机启动： chkconfig ntpd on修改/etc/ntp.conf 将restrict default kod nomodify notrap nopeer noquery注释掉，这个对客户端的限制太多。ntp 4.2之前版本添加restrict default nomodify notrust（允许任何IP的客户机都可以进行时间同步）以允许所有客户端获取时间数据。notrust 参数的功能是并需通过认证才能同步，也就是客户端同步命令中必须有keyid和key才能通过。 注释掉所有的trustedkey， 添加 trustedkey 1 2 3，后边指定数字任意，但必须与/etc/ntp/keys文件中的 值保持一致。也就是说1 2 3 这三个数分别作为认证的keyid。 配置时间源， 指定同步参考的服务器时间。如果连接不了外网就把所有外网时间服务器都注释掉 123server 10.148.27.166 // 局域网内，客户机（slaver）配置为集群内master服务器IPserver ntp.api.bz // 连接不了外网就注释掉server 2.centos.pool.ntp.org // 连接不了外网就注释掉 添加如下配置项目，以让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端。 客户端不需要配置，只在服务端配置即可 12server 127.127.1.0 # local clock //服务端如果连接不了外网，使用本地时间提供给客户端同步fudge 127.127.1.0 stratum 2 最后保存退出 修改/etc/ntp/keys文件（集群内所在节点）添加如下配置， 前面的数字必须与 /etc/ntp.conf 文件中 trustedkey 后边指定的数字一致才行，字符串任意。 1231 M gao2 M tian3 M di 修改时区12rm -f /etc/localtimecp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 重启 ntp 服务 service ntpd restart 要注意ntp的重启是有延迟的，所以有的时候重启以后没发现修改配置生效，是因为这个延迟导致的， 这是因为NTP server还没有和其自身或者它的server同步上 如果集群内所在节点都安装了NTP服务，服务端时间源外网时间源不可用时，可与本地时间同步，且客户端时间源配置了集群内服务端，那么启动所有节点NTP服务，集群内节点即可实现时间同步。 如果客户端NTP服务未启动，或者未配置集群内时间源，可通过执行 ntpdate &lt;ntp server&gt; 来同步，我们只要指定与master节点同步就可以了。 手动在集群内所客户端系统上执行 ntpdate 10.148.27.166 ，测试服务器是否成功配置；1成功返回：ntpdate[15522]: adjust time server 10.148.27.166 offset 0.290456 sec 同步调试模式1ntpdate -d 10.148.27.166 常见问题问题一： 10.148.27.166: Server dropped: no data ntp 4.2（包括4.2）之后的版本，在restrict的定义中使用notrust的话，会导致以上错误。使用以下命令查看ntp版本： 1ntpq -c version 检查ntp server的防火墙，可能是server的防火墙屏蔽了upd 123端口可关闭防火墙试试，若同步成功，说明是防火墙问题，开启防火墙端口即可。关闭防火墙： 1service iptables stop 问题二： 10.148.27.166: Server dropped: Strata too highstartum的值正常情况下为0~15，修改/etc/ntp.conf中：startum后面的值在0~15之间即可。 问题三： 一直提示step time server重启 ntp service ntpd restart ，还没有解决稍等一下再手动同步 成功返回adjust time server 10.148.27.166 offset 0.000073 sec 常用命令12345678# 查看ntp版本ntpq -c versionntpdate -u ip# NTP服务状态ntpstatntpq -p# 查看NTP服务的运行状况watch ntpq -p]]></content>
      <categories>
        <category>Linux</category>
        <category>NTP</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机网络模式]]></title>
    <url>%2Fposts%2F2017%2F10%2F09%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1. 桥接bridge桥接网络是指本地物理网卡和虚拟网卡通过VMnet0虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位，那么物理网卡和虚拟网卡就相当于处于同一个网段，虚拟交换机就相当于一台现实网络中的交换机,所以两个网卡的IP地址也要设置为同一网段。所以当我们要在局域网使用虚拟机，对局域网其他pc提供服务时，例如提供ftp，提供ssh，提供http服务，那么就要选择桥接模式。 2. NAT（共享主机的IP地址）即让虚拟机借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。 NAT模式中，虚拟机的网卡和物理网卡的网络，不在同一个网络，虚拟机的网卡，是在vmware提供的一个虚拟网络。 NAT和桥接的比较: NAT模式和桥接模式虚拟机都可以上外网。 由于NAT的网络在vmware提供的一个虚拟网络里，所以局域网其他主机是无法访问虚拟机的，而宿主机可以访问虚拟机，虚拟机可以访问局域网的所有主机，因为真实的局域网相对于NAT的虚拟网络，就是NAT的虚拟网络的外网，不懂的人可以查查NAT的相关知识。 桥接模式下，多个虚拟机之间可以互相访问；NAT模式下，多个虚拟机之间也可以相互访问。 3. Host-Only（仅主机模式）在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实Host-Only网络和NAT网络很相似，不同的地方就是Host-Only网络没有NAT服务，所以虚拟网络不能连接到Internet。主机和虚拟机之间的通信是通过VMware Network Adepter VMnet1虚拟网卡来实现的。 Host-Only的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。这个功能或许对普通用户来说没有多大意义，但大型服务商会常常利用这个功能。如果你想为VMnet1网段提供路由功能，那就需要使用RRAS，而不能使用XP或2000的ICS，因为ICS会把内网的IP地址改为192.168.0.1，但虚拟机是不会给VMnet1虚拟网卡分配这个地址的，那么主机和虚拟机之间就不能通信了。]]></content>
      <categories>
        <category>虚拟机</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机(Vmware)NAT模式使用静态IP上网]]></title>
    <url>%2Fposts%2F2017%2F10%2F09%2F%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E6%A8%A1%E5%BC%8F%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81IP%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[1. VMnet8虚拟网卡设置界面：这里不要勾选使用DHCP服务分配IP地址给虚拟机选项。然后配置子网IP，子网IP与宿主机的ip一定不能处在同一地址范围里，否则就算虚拟机能上网，网络既慢，还不稳定。例如主机的ip段是192.168.115.xxx，子网IP配为192.168.10.xxx来避开主机的ip段 点击上图中的NAT 设置，设置网关IP，如图： 2. 配置ifcfg-ethXX文件123456789101112DEVICE="eth0"BOOTPROTO="static"HWADDR="00:0C:29:93:F1:48"IPV6INIT="yes"NM_CONTROLLED="yes"ONBOOT="yes"TYPE="Ethernet"UUID="b2b2b49b-6be0-480e-a026-ee7c3a4aca28"IPADDR="192.168.11.100"NETMASK="255.255.255.0"GATEWAY="192.168.11.2"DNS1=8.8.8.8 BOOTPROTO：改为static GATEWAY：设为刚才设置的 IPADDR：配置ip，在第一步已经设置ip处于192.168.11.xxx这个范围，这里设置为100，只要不和网关相同均可3. 保存，如果没有自动重启网卡，运行service network restart，应该就能上网了]]></content>
      <categories>
        <category>虚拟机</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sed命令在Linux上的使用指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F06%2FSed%E5%91%BD%E4%BB%A4%E5%9C%A8Linux%E4%B8%8A%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[删除删除第三行：1sed -i '3d' 1.txt 删除以winter开头的行1sed -i '/^winter/d' 1.txt 删除包含winter（特殊字符需要转义）的行1sed -i '/winter/d' 1.txt 插入在14行下插入新的一行：aaaaaa1sed -i 14a\aaaaaaa 1.txt 查询查询winter在文件中的行号1sed -ne '/winter/=' 1.txt 修改将文件中的_SUPERMODELIPPORT替换为$SMIPPORT，g代表全局替换，不加g替换第一个1sed -i "s%_SUPERMODELIPPORT%$SMIPPORT%g" 1.txt 修改第$ROW行为&#39;$HOST&#39; &#39;$HOSTNAME1sed -i -e $ROW'c\'$HOST' '$HOSTNAME 1.txt]]></content>
      <categories>
        <category>Linux</category>
        <category>sed</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 新机器检查基础环境]]></title>
    <url>%2Fposts%2F2017%2F10%2F06%2F%E6%96%B0%E6%9C%BA%E5%99%A8%E6%A3%80%E6%9F%A5%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[系统信息： cat /etc/redhat-release , uname -a, lsb_release -a cpu信息： cat /proc/cpuinfo ，是否升级内核 内存信息： free -h， cat /proc/meminfo 磁盘信息： df -lhT ，挂载路径 网卡信息： ip a , ifconfig, ethtool devname |grep -i speed Linux系统时间： date 主机名，ip和主机名映射: hostname,vim /etc/hosts yum源： 是否修改/etc/yum.repos.d 时钟同步：web服务器、solr机器（必须） ssh互信：web服务器、solr机器 查看系统信息查看CPU信息查看CPU信息（型号）1cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 查看物理CPU个数1cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l 查看每个物理CPU中core的个数(即核数)1cat /proc/cpuinfo| grep "cpu cores"| uniq 查看逻辑CPU的个数1cat /proc/cpuinfo| grep "processor"| wc -l 总核数 = 物理CPU个数 X 每颗物理CPU的核数 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 查看内存信息运行 grep -i commit /proc/meminfo 查看系统内存分配状态12345[root@localhost local]# grep -i commit /proc/meminfoCommitLimit: 15550904 kBCommitted_AS: 15098404 kB# CommitLimit是一个内存分配上限,CommitLimit = 物理内存 * overcommit_ratio(默认50，即50%) + swap大小# Committed_As是已经分配的内存大小。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统基础环境设置]]></title>
    <url>%2Fposts%2F2017%2F10%2F02%2FLinux%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[更换本地yum源从ustc下载.repo文件，切换源1cd /etc/yum.repos.d/ 将原有xx.repo文件全部改名为xx.repo.bak(rename .repo .repo.bak *.repo)1234567# wget https://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/centos?codeblock=1-O CentOS-ustc.repo 【centos5 ustc源】wget https://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/centos?codeblock=2 -O CentOS-ustc.repo【centos6 ustc源】# wget https://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/centos?codeblock=3 -O CentOS-ustc.repo 【centos7 ustc源】yum clean allyum makecache 检查源是否切换成功12yum list#看到很多列表表示成功 修改主机名永久修改，需重启12345[root@hadoop-01 ~]# vim /etc/sysconfig/network#NETWORKING=yesNETWORKING=yesNETWORKING_IPV6=noHOSTNAME=hadoop-01 临时修改，立即生效（重启失效）123[root@hadoop-01 ~]# hostname hh[root@hadoop-01 ~]# hostnamehh 修改host文件（ip地址和主机名绑定）123456[root@hadoop-01 ~]# vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.115 hadoop-01192.168.1.116 hadoop-02 192.168.1.117 hadoop-03 禁用IP6没有做过12345678910111213141516vi /etc/sysconfig/network在最后增加一句：IPV6INIT=nocat /etc/sysconfig/networkNETWORKING=yesIPV6INIT=no//修改hosts文件，注释ip6#vi /etc/hosts127.0.0.1 localhost.localdomain localhost #::1 localhost6.localdomain6 localhost6//立即停止IP6服务service ip6tables stop//永久停止ipv6的iptableschkconfig ip6tables off 关闭防火墙1234#立即停止 （暂时停止，重启失效）service iptables stop#永久停止chkconfig iptables off #禁用 禁用SELINUX1vim /etc/selinux/config 将SELINUX=enforcing改为SELINUX=disabled 修改默认启动级别1234vim /etc/inittab#默认为5：图形界面的多用户#修改为3：带网络的多用户id:3:initdefault: 设置Linux系统时区1234567891011TZ=Asia/Shanghailn -snf /usr/share/zoneinfo/$TZ /etc/localtimeecho $TZ &gt; /etc/timezone``` # 设置系统（CentOS6.7）编码```bashvim /etc/sysconfig/i18nLANG="en_US.UTF-8"LANGUAGE="en_US:en"LC_ALL="en_US.UTF-8"]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker17.09在CentOS7上的部署指南]]></title>
    <url>%2Fposts%2F2017%2F10%2F02%2FDocker17-09%E5%9C%A8CentOS7%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[Uninstall old versions1234$ sudo yum remove docker \ docker-common \ docker-selinux \ docker-engine Install Docker CEYou can install Docker CE in different ways, depending on your needs: Most users set up Docker’s repositories and install from them, for ease of installation and upgrade tasks. This is the recommended approach. Some users download the RPM package and install it manually and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet. In testing and development environments, some users choose to use automated convenience scripts to install Docker. Install using the repositoryBefore you install Docker CE for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository. Set up the repository Install required packages. 1$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2 Use the following command to set up the stable repository. You always need the stable repository, even if you want to install builds from the edge or test repositories as well. 123$ sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo Optional: Enable the edge and test repositories. These repositories are included in the docker.repo file above but are disabled by default. You can enable them alongside the stable repository. 1$ sudo yum-config-manager --enable docker-ce-edge 1$ sudo yum-config-manager --enable docker-ce-test You can disable the edge or test repository by running the yum-config-manager command with the --disable flag. To re-enable it, use the --enable flag. The following command disables the edge repository.1$ sudo yum-config-manager --disable docker-ce-edge Note: Starting with Docker 17.06, stable releases are also pushed to the edge and test repositories. Install Docker CE Update the yum package index.1$ sudo yum makecache fast Install the latest version of Docker CE, or go to the next step to install a specific version.1sudo yum install docker-ce Warning: If you have multiple Docker repositories enabled, installing or updating without specifying a version in the yum install or yum update command will always install the highest possible version, which may not be appropriate for your stability needs. On production systems, you should install a specific version of Docker CE instead of always using the latest. List the available versions. This example uses the sort -r command to sort the results by version number, highest to lowest, and is truncated. Note: This yum list command only shows binary packages. To show source packages as well, omit the .x86_64 from the package name. 123$ yum list docker-ce.x86_64 --showduplicates | sort -rdocker-ce.x86_64 17.06.0.el7 docker-ce-stable The contents of the list depend upon which repositories are enabled, and will be specific to your version of CentOS (indicated by the .el7 suffix on the version, in this example). Choose a specific version to install. The second column is the version string. The third column is the repository name, which indicates which repository the package is from and by extension its stability level. To install a specific version, append the version string to the package name and separate them by a hyphen (-):1$ sudo yum install docker-ce-&lt;VERSION&gt; Start Docker. 1$ sudo systemctl start docker Verify that docker is installed correctly by running the hello-world image. 1$ sudo docker run hello-world This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits. Upgrade Docker CE To upgrade Docker CE, first run sudo yum makecache fast, then follow the installation instructions, choosing the new version you want to install. Install from a packageIf you cannot use Docker’s repository to install Docker, you can download the .rpm file for your release and install it manually. You will need to download a new file each time you want to upgrade Docker. Go to https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ and download the .rpm file for the Docker version you want to install. Note: To install an edge package, change the word stable in the &gt; URL to edge. Install Docker CE, changing the path below to the path where you downloaded the Docker package. 1$ sudo yum install /path/to/package.rpm Start Docker. 1$ sudo systemctl start docker Verify that docker is installed correctly by running the hello-world image. 1$ sudo docker run hello-world Install using the convenience scriptreference https://docs.docker.com/engine/installation/linux/docker-ce/centos/#install-using-the-convenience-script Uninstall Docker CE Uninstall the Docker package: 1$ sudo yum remove docker-ce Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes: 1$ sudo rm -rf /var/lib/docker You must delete any edited configuration files manually. 常见问题附录清空容器日志查看容器详细信息1docker inspect ContainerID 找到LogPath的值 /var/log/......log-json.log，运行1cat /dev/null &gt; /var/log/......log-json.log]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github相关]]></title>
    <url>%2Fposts%2F2017%2F10%2F02%2FGithub%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[为github帐号添加SSH keys使用git clone命令从github上同步github上的代码库时，如果使用SSH链接（如我自己的beagleOS项 目：git@github.com:DamonDeng/beagleOS.git），而你的SSH key没有添加到github帐号设置中，系统会报下面的错误：12Permission denied (publickey).fatal: The remote end hung up unexpectedly 这时需要在本地创建SSH key，然后将生成的SSH key文件内容添加到github帐号上去。创建SSH key的方法很简单，执行如下命令就可以：ssh-keygen然后系统提示输入文件保存位置等信息，连续敲三次回车即可，生成的SSH key文件保存在中～/.ssh/id_rsa.pub 然后用文本编辑工具打开该文件，我用的是vim,所以命令是：vim ~/.ssh/id_rsa.pub 接着拷贝.ssh/id_rsa.pub文件内的所以内容，将它粘帖到github帐号管理中的添加SSH key界面中。打开github帐号管理中的添加SSH key界面的步骤如下： 登录github 点击右上方的Accounting settings图标 选择 SSH key 点击 Add SSH key在出现的界面中填写SSH key的名称，填一个你自己喜欢的名称即可，然后将上面拷贝的~/.ssh/id_rsa.pub文件内容粘帖到key一栏，在点击“add key”按钮就可以了。添加过程github会提示你输入一次你的github密码 添加完成后再次执行git clone就可以成功克隆github上的代码库了。 来源： http://blog.csdn.net/keyboardota/article/details/7603630 等等]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>Github</tag>
      </tags>
  </entry>
</search>
